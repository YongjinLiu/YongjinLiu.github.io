---
title: "Real-Time Movie-Induced Discrete Emotion Recognition from EEG Signals"
collection: publications
permalink: /publication/2018-Real-Time-Movie-Induced-Discrete-Emotion-Recognition-from-EEG-Signals
excerpt: ''
date: 2017-01-27
venue: ' IEEE Transactions on Affective Computing'
tags:
  - Journal Publications
citation: 'Yong-Jin Liu, Minjing Yu, Guozhen Zhao, Jinjing Song, Yan Ge, Yuanchun Shi. Real-Time Movie-Induced Discrete Emotion Recognition from EEG Signals. IEEE Transactions on Affective Computing, Vol. 9, No. 4, pp. 550-562, 2018.'
---

Abstract: Recognition of a human's continuous emotional states in real time plays an important role in machine emotional intelligence and human-machine interaction. Existing real-time emotion recognition systems use stimuli with low ecological validity (e.g., picture, sound) to elicit emotions and to recognise only valence and arousal. To overcome these limitations, in this paper, we construct a standardised database of 16 emotional film clips that were selected from over one thousand film excerpts. Based on emotional categories that are induced by these film clips, we propose a real-time movie-induced emotion recognition system for identifying an individual's emotional states through the analysis of brain waves. Thirty participants took part in this study and watched 16 standardised film clips that characterise real-life emotional experiences and target seven discrete emotions and neutrality. Our system uses a 2-s window and a 50 percent overlap between two consecutive windows to segment the EEG signals. Emotional states, including not only the valence and arousal dimensions but also similar discrete emotions in the valence-arousal coordinate space, are predicted in each window. Our real-time system achieves an overall accuracy of 92.26 percent in recognising high-arousal and valenced emotions from neutrality and 86.63 percent in recognising positive from negative emotions. Moreover, our system classifies three positive emotions (joy, amusement, tenderness) with an average of 86.43 percent accuracy and four negative emotions (anger, disgust, fear, sadness) with an average of 65.09 percent accuracy. These results demonstrate the advantage over the existing state-of-the-art real-time emotion recognition systems from EEG signals in terms of classification accuracy and the ability to recognise similar discrete emotions that are close in the valence-arousal coordinate space.



[Download paper here](http://yongjinliu.github.io/files/2018-Real-Time-Movie-Induced-Discrete-Emotion-Recognition-from-EEG-Signals.pdf)

Recommended citation: Yong-Jin Liu, Minjing Yu, Guozhen Zhao, Jinjing Song, Yan Ge, Yuanchun Shi. Real-Time Movie-Induced Discrete Emotion Recognition from EEG Signals. IEEE Transactions on Affective Computing, Vol. 9, No. 4, pp. 550-562, 2018.

